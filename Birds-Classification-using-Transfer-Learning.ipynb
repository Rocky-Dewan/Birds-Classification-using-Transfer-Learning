{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5205289,"sourceType":"datasetVersion","datasetId":3027308}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:39:40.955238Z","iopub.execute_input":"2025-05-13T04:39:40.955475Z","iopub.status.idle":"2025-05-13T04:39:42.125477Z","shell.execute_reply.started":"2025-05-13T04:39:40.955457Z","shell.execute_reply":"2025-05-13T04:39:42.124714Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom sklearn.metrics import classification_report, f1_score , confusion_matrix\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:39:42.126259Z","iopub.execute_input":"2025-05-13T04:39:42.126590Z","iopub.status.idle":"2025-05-13T04:39:42.595152Z","shell.execute_reply.started":"2025-05-13T04:39:42.126566Z","shell.execute_reply":"2025-05-13T04:39:42.594293Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Rescaling, RandomFlip, RandomRotation, RandomZoom\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import layers, models, Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import mixed_precision\n\nmixed_precision.set_global_policy('mixed_float16')\n\nprint(tf.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:39:42.597007Z","iopub.execute_input":"2025-05-13T04:39:42.597314Z","iopub.status.idle":"2025-05-13T04:39:54.902515Z","shell.execute_reply.started":"2025-05-13T04:39:42.597297Z","shell.execute_reply":"2025-05-13T04:39:54.901875Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = {\n             \"train_data\" : \"/kaggle/input/indian-birds/Birds_25/train\",\n             \"valid_data\" : \"/kaggle/input/indian-birds/Birds_25/valid\",\n          }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:39:54.903155Z","iopub.execute_input":"2025-05-13T04:39:54.903631Z","iopub.status.idle":"2025-05-13T04:39:54.908043Z","shell.execute_reply.started":"2025-05-13T04:39:54.903611Z","shell.execute_reply":"2025-05-13T04:39:54.907348Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nall_data = []\nfor path in dataset.values():\n    data = {\"imgpath\": [] , \"labels\": [] }\n    category = os.listdir(path)\n\n    for folder in category:\n        folderpath = os.path.join(path , folder)\n        filelist = os.listdir(folderpath)\n        for file in filelist:\n            fpath = os.path.join(folderpath, file)\n            data[\"imgpath\"].append(fpath)\n            data[\"labels\"].append(folder)\n        \n        \n    all_data.append(data.copy())\n    data.clear()\n\n    \n    \ntrain_df = pd.DataFrame(all_data[0] , index=range(len(all_data[0]['imgpath'])))\nvalid_df = pd.DataFrame(all_data[1] , index=range(len(all_data[1]['imgpath'])))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:39:54.908885Z","iopub.execute_input":"2025-05-13T04:39:54.909208Z","iopub.status.idle":"2025-05-13T04:39:55.911961Z","shell.execute_reply.started":"2025-05-13T04:39:54.909184Z","shell.execute_reply":"2025-05-13T04:39:55.911357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#Convert labels to numbers\nlb = LabelEncoder()\ntrain_df['encoded_labels'] = lb.fit_transform(train_df['labels'])\nvalid_df['encoded_labels'] = lb.fit_transform(valid_df['labels'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:39:55.912731Z","iopub.execute_input":"2025-05-13T04:39:55.912982Z","iopub.status.idle":"2025-05-13T04:39:55.927768Z","shell.execute_reply.started":"2025-05-13T04:39:55.912962Z","shell.execute_reply":"2025-05-13T04:39:55.927114Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid_df , test_df = train_test_split(valid_df ,  train_size= 0.95 , shuffle=True, random_state=124)\nvalid_df = valid_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:39:55.928568Z","iopub.execute_input":"2025-05-13T04:39:55.928772Z","iopub.status.idle":"2025-05-13T04:39:55.948359Z","shell.execute_reply.started":"2025-05-13T04:39:55.928755Z","shell.execute_reply":"2025-05-13T04:39:55.947846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train  = train_df[\"labels\"].value_counts()\nlabel = train.tolist()\nindex = train.index.tolist()\n\ncolors = [\n    \"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\",\n    \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\",\n    \"#aec7e8\", \"#ffbb78\", \"#98df8a\", \"#ff9896\", \"#c5b0d5\",\n    \"#c49c94\", \"#f7b6d2\", \"#c7c7c7\", \"#dbdb8d\", \"#9edae5\",\n    \"#5254a3\", \"#6b6ecf\", \"#bdbdbd\", \"#8ca252\", \"#bd9e39\",\n    \"#ad494a\", \"#8c6d31\", \"#6b6ecf\", \"#e7ba52\", \"#ce6dbd\",\n    \"#9c9ede\", \"#cedb9c\", \"#de9ed6\", \"#ad494a\", \"#d6616b\",\n    \"#f7f7f7\", \"#7b4173\", \"#a55194\", \"#ce6dbd\"\n]\n\n\n\nplt.figure(figsize=(17,17))\nplt.title(\"Training data images count per class\",fontsize=38)\nplt.xlabel('Number of images', fontsize=35)\nplt.ylabel('Classes', fontsize=35)\nplt.barh(index,label, color=colors)\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:39:55.949000Z","iopub.execute_input":"2025-05-13T04:39:55.949174Z","iopub.status.idle":"2025-05-13T04:39:56.430818Z","shell.execute_reply.started":"2025-05-13T04:39:55.949159Z","shell.execute_reply":"2025-05-13T04:39:56.429962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.sample(n=15, random_state=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:39:56.433285Z","iopub.execute_input":"2025-05-13T04:39:56.433943Z","iopub.status.idle":"2025-05-13T04:39:56.452367Z","shell.execute_reply.started":"2025-05-13T04:39:56.433923Z","shell.execute_reply":"2025-05-13T04:39:56.451688Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"----------Train-------------\")\nprint(train_df[[\"imgpath\", \"labels\"]].head(5))\nprint(train_df.shape)\nprint(\"--------Validation----------\")\nprint(valid_df[[\"imgpath\", \"labels\"]].head(5))\nprint(valid_df.shape)\nprint(\"----------Test--------------\")\nprint(test_df[[\"imgpath\", \"labels\"]].head(5))\nprint(test_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:39:56.453091Z","iopub.execute_input":"2025-05-13T04:39:56.453322Z","iopub.status.idle":"2025-05-13T04:39:56.464765Z","shell.execute_reply.started":"2025-05-13T04:39:56.453307Z","shell.execute_reply":"2025-05-13T04:39:56.463936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(15,12))\nfor i, row in valid_df.sample(n=16).reset_index().iterrows():\n    plt.subplot(4,4,i+1)\n    image_path = row['imgpath']\n    image = Image.open(image_path)\n    plt.imshow(image)\n    plt.title(row[\"labels\"])\n    plt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:39:56.465524Z","iopub.execute_input":"2025-05-13T04:39:56.465702Z","iopub.status.idle":"2025-05-13T04:39:58.993886Z","shell.execute_reply.started":"2025-05-13T04:39:56.465688Z","shell.execute_reply":"2025-05-13T04:39:58.992871Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\nBATCH_SIZE = 50\nIMAGE_SIZE = (224, 224)\n\n\ngenerator = ImageDataGenerator(\n    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n    # there could be image augmentation here\n)\n\n# Split the data into three categories.\ntrain_images = generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='imgpath',\n    y_col='labels',\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=42,\n)\n\nval_images = generator.flow_from_dataframe(\n    dataframe=valid_df,\n    x_col='imgpath',\n    y_col='labels',\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)\n\ntest_images = generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='imgpath',\n    y_col='labels',\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:39:58.994701Z","iopub.execute_input":"2025-05-13T04:39:58.995001Z","iopub.status.idle":"2025-05-13T04:40:34.554437Z","shell.execute_reply.started":"2025-05-13T04:39:58.994981Z","shell.execute_reply":"2025-05-13T04:40:34.553836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the pretained model\npretrained_model = tf.keras.applications.EfficientNetB3(\n    input_shape=(224, 224, 3),\n    include_top=False, # we don`t need a pre-trained top layer (output layer)\n    weights='imagenet',\n    pooling='max'\n)\n\n# Freezing the layers of a pretrained neural network\nfor i, layer in enumerate(pretrained_model.layers):\n    pretrained_model.layers[i].trainable = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:40:34.555214Z","iopub.execute_input":"2025-05-13T04:40:34.555510Z","iopub.status.idle":"2025-05-13T04:40:39.400872Z","shell.execute_reply.started":"2025-05-13T04:40:34.555487Z","shell.execute_reply":"2025-05-13T04:40:39.400312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomContrast\n\nnum_classes = len(set(train_images.classes))\n\n\n# Data Augmentation Step\naugment = tf.keras.Sequential([\n    RandomFlip(\"horizontal\"),\n    RandomRotation(0.1),\n    RandomZoom(0.1),\n    RandomContrast(0.1),\n], name='AugmentationLayer')\n\n\n\ninputs = layers.Input(shape = (224,224,3), name='inputLayer')\nx = augment(inputs)\npretrain_out = pretrained_model(x, training = False)\nx = layers.Dense(256)(pretrain_out)\nx = layers.Activation(activation=\"relu\")(x) \nx = BatchNormalization()(x)\nx = layers.Dropout(0.3)(x)\nx = layers.Dense(num_classes)(x)\noutputs = layers.Activation(activation=\"softmax\", dtype=tf.float32, name='activationLayer')(x) # mixed_precision need separated Dense and Activation layers\nmodel = Model(inputs=inputs, outputs=outputs)\n\n\n\nmodel.compile(\n    optimizer=Adam(0.0005),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(model.summary())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:40:39.401639Z","iopub.execute_input":"2025-05-13T04:40:39.401889Z","iopub.status.idle":"2025-05-13T04:40:39.487394Z","shell.execute_reply.started":"2025-05-13T04:40:39.401861Z","shell.execute_reply":"2025-05-13T04:40:39.486841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=5,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min')\n    ]\n)\n\n\n#model.save_weights('./checkpoints/my_checkpoint.weights.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:40:39.488318Z","iopub.execute_input":"2025-05-13T04:40:39.488904Z","iopub.status.idle":"2025-05-13T05:03:09.443434Z","shell.execute_reply.started":"2025-05-13T04:40:39.488879Z","shell.execute_reply":"2025-05-13T05:03:09.442640Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Ensure the directory exists\ncheckpoint_dir = './checkpoints'\nif not os.path.exists(checkpoint_dir):\n    os.makedirs(checkpoint_dir)\n\n# Now you can safely save the model weights\nmodel.save_weights(os.path.join(checkpoint_dir, 'my_checkpoint.weights.h5'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T05:03:09.444543Z","iopub.execute_input":"2025-05-13T05:03:09.444781Z","iopub.status.idle":"2025-05-13T05:03:10.053315Z","shell.execute_reply.started":"2025-05-13T05:03:09.444763Z","shell.execute_reply":"2025-05-13T05:03:10.052566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(train_images))  # Number of batches\nprint(train_images.samples)  # Total number of images\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T05:03:10.054405Z","iopub.execute_input":"2025-05-13T05:03:10.054654Z","iopub.status.idle":"2025-05-13T05:03:10.059644Z","shell.execute_reply.started":"2025-05-13T05:03:10.054635Z","shell.execute_reply":"2025-05-13T05:03:10.058904Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define needed variables\ntr_acc = history.history['accuracy']\ntr_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n\n# Plot training history\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\n\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T05:03:10.060461Z","iopub.execute_input":"2025-05-13T05:03:10.060830Z","iopub.status.idle":"2025-05-13T05:03:10.536241Z","shell.execute_reply.started":"2025-05-13T05:03:10.060809Z","shell.execute_reply":"2025-05-13T05:03:10.535440Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pretrained_model.trainable = True\nfor layer in pretrained_model.layers:\n    if isinstance(layer, layers.BatchNormalization): # set BatchNorm layers as not trainable\n        layer.trainable = False\n        \n# let`s see first 10 layers\nfor l in pretrained_model.layers[:10]:\n    print(l.name, l.trainable)\n\nmodel.compile(\n    optimizer=Adam(0.00001), # fine tuning requires very little learning rate\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n# model.load_weights('./checkpoints/my_checkpoint')\nprint(model.summary())\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=6,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min')\n    ]\n)\n\n\n#model.save_weights('./checkpoints/my_checkpoint')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T05:03:10.537077Z","iopub.execute_input":"2025-05-13T05:03:10.537295Z","iopub.status.idle":"2025-05-13T05:27:56.367110Z","shell.execute_reply.started":"2025-05-13T05:03:10.537278Z","shell.execute_reply":"2025-05-13T05:27:56.366313Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Ensure the directory exists\ncheckpoint_dir = './checkpoints'\nif not os.path.exists(checkpoint_dir):\n    os.makedirs(checkpoint_dir)\n\n# Now you can safely save the model weights\nmodel.save_weights(os.path.join(checkpoint_dir, 'my_checkpoint.weights.h5'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T05:27:56.368171Z","iopub.execute_input":"2025-05-13T05:27:56.368426Z","iopub.status.idle":"2025-05-13T05:27:57.006751Z","shell.execute_reply.started":"2025-05-13T05:27:56.368404Z","shell.execute_reply":"2025-05-13T05:27:57.005868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define needed variables\ntr_acc = history.history['accuracy']\ntr_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n\n# Plot training history\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\n\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T05:27:57.007872Z","iopub.execute_input":"2025-05-13T05:27:57.008057Z","iopub.status.idle":"2025-05-13T05:27:57.426953Z","shell.execute_reply.started":"2025-05-13T05:27:57.008043Z","shell.execute_reply":"2025-05-13T05:27:57.426179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, LeakyReLU, Rescaling\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Sequential\n\n# Example: You must already define `pretrained_model` and datasets: train_images, val_images\n\nnum_classes = len(set(train_images.classes))\n\n# Data Augmentation Step\naugment = Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.2),\n    layers.RandomZoom(0.2),\n    layers.RandomContrast(0.2),\n], name='AugmentationLayer')\n\n# Model architecture with modifications\ninputs = Input(shape=(224, 224, 3), name='inputLayer')\nx = Rescaling(1./255)(inputs)  # Normalize inputs\nx = augment(x)\n\npretrain_out = pretrained_model(x, training=False)\n\nx = Dense(512)(pretrain_out)\nx = LeakyReLU()(x)\nx = BatchNormalization()(x)\nx = Dropout(0.4)(x)\n\nx = Dense(256)(x)\nx = LeakyReLU()(x)\nx = BatchNormalization()(x)\nx = Dropout(0.3)(x)\n\nx = Dense(128)(x)\nx = LeakyReLU()(x)\nx = Dropout(0.2)(x)\n\nx = Dense(num_classes)(x)\noutputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"activationLayer\")(x)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T05:46:26.137329Z","iopub.execute_input":"2025-05-13T05:46:26.137611Z","iopub.status.idle":"2025-05-13T05:46:26.207604Z","shell.execute_reply.started":"2025-05-13T05:46:26.137593Z","shell.execute_reply":"2025-05-13T05:46:26.207084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Unfreeze pretrained model for fine-tuning, except BatchNorm layers\npretrained_model.trainable = True\nfor layer in pretrained_model.layers:\n    if isinstance(layer, layers.BatchNormalization):\n        layer.trainable = False\n\n# View first 10 layers and their trainable status\nfor l in pretrained_model.layers[:10]:\n    print(l.name, l.trainable)\n\n# Compile with low learning rate for fine-tuning\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-5),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Train the model\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=6,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min')\n    ]\n)\n\n\n# model.save_weights('./checkpoints/my_checkpoint.weights.h5')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T05:46:31.321194Z","iopub.execute_input":"2025-05-13T05:46:31.321879Z","iopub.status.idle":"2025-05-13T06:20:06.319950Z","shell.execute_reply.started":"2025-05-13T05:46:31.321855Z","shell.execute_reply":"2025-05-13T06:20:06.319159Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import BatchNormalization, Dropout\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n\npretrained_model = EfficientNetB3(include_top=False, input_shape=(224, 224, 3), pooling='avg')\n\n\nnum_classes = len(set(train_images.classes))\n\n\naugment = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.15),.9346 - loss: 0.2311 - val_accuracy: 0.9335 - val_loss: 0.2317 - learning_rate: 5.0000e-04\n    layers.RandomZoom(0.2),\n    layers.RandomContrast(0.2),\n], name='AugmentationLayer')\n\n\ninputs = layers.Input(shape=(224, 224, 3), name='inputLayer')\nx = augment(inputs)\nx = layers.Rescaling(1./255)(x)  \n\n\nx = pretrained_model(x, training=False)\n\n\nx = layers.Dense(512)(x)\nx = layers.LeakyReLU()(x)\nx = Dropout(0.4)(x)\nx = BatchNormalization()(x)\n\nx = layers.Dense(256, activation='relu')(x)\nx = Dropout(0.3)(x)\n\nx = layers.Dense(128, activation='relu')(x)\n\nx = layers.Dense(num_classes)(x)\noutputs = layers.Activation(\"softmax\", dtype=tf.float32, name='activationLayer')(x)\n\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\n\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0005),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nmodel.summary()\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=5,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min')\n    ]\n)\n\n\n# model.save_weights('./checkpoints/efficientnetb3_custom_checkpoint.h5')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:29:12.202066Z","iopub.execute_input":"2025-05-13T06:29:12.202333Z","iopub.status.idle":"2025-05-13T07:15:11.131999Z","shell.execute_reply.started":"2025-05-13T06:29:12.202314Z","shell.execute_reply":"2025-05-13T07:15:11.131320Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = model.evaluate(test_images, verbose=0)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T07:15:15.880654Z","iopub.execute_input":"2025-05-13T07:15:15.880921Z","iopub.status.idle":"2025-05-13T07:15:19.294972Z","shell.execute_reply.started":"2025-05-13T07:15:15.880900Z","shell.execute_reply":"2025-05-13T07:15:19.294368Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true = test_images.classes\ny_pred = np.argmax(model.predict(test_images), axis = 1)\nf1 = f1_score(y_true, y_pred, average='macro')\nprint(\"F1 Score:\", f1)\nprint(classification_report(y_true, y_pred, target_names=test_images.class_indices.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T05:28:02.110307Z","iopub.execute_input":"2025-05-13T05:28:02.110591Z","iopub.status.idle":"2025-05-13T05:28:15.988655Z","shell.execute_reply.started":"2025-05-13T05:28:02.110565Z","shell.execute_reply":"2025-05-13T05:28:15.987803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classes = dict(zip(test_images.class_indices.values(), test_images.class_indices.keys()))\nPredictions = pd.DataFrame({\"Image Index\" : list(range(len(test_images.labels))), \n                            \"Test Labels\" : test_images.labels, \n                            \"Test Classes\" : [classes[i] for i in test_images.labels],\n                            \"Prediction Labels\" : y_pred,\n                            \"Prediction Classes\" : [classes[i] for i in y_pred],\n                            \"Path\": test_images.filenames,\n                            \"Prediction Probability\" : [x for x in np.asarray(tf.reduce_max(model.predict(test_images), axis = 1))]\n                           })\nPredictions.head(8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T05:28:15.989488Z","iopub.execute_input":"2025-05-13T05:28:15.990017Z","iopub.status.idle":"2025-05-13T05:28:18.942471Z","shell.execute_reply.started":"2025-05-13T05:28:15.989998Z","shell.execute_reply":"2025-05-13T05:28:18.941814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\nfor i, row in Predictions[Predictions[\"Test Labels\"] != Predictions[\"Prediction Labels\"]].sort_values(\"Prediction Probability\").tail(20).reset_index().iterrows():\n    plt.subplot(5,4,i+1)\n    image_path = row['Path']\n    image = Image.open(image_path)\n    plt.imshow(image)\n    plt.title(f'TRUE: {row[\"Test Classes\"]} | PRED: {row[\"Prediction Classes\"]}', fontsize=8)\n    plt.axis('off')\n    \nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T05:28:18.943142Z","iopub.execute_input":"2025-05-13T05:28:18.943377Z","iopub.status.idle":"2025-05-13T05:28:22.050613Z","shell.execute_reply.started":"2025-05-13T05:28:18.943360Z","shell.execute_reply":"2025-05-13T05:28:22.049514Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\n# Predict using model.predict() instead of predict_generator()\npreds = model.predict(test_images)  # ✅ This works for generators now\ny_pred = np.argmax(preds, axis=1)\n\n# Get class labels\ng_dict = test_images.class_indices\nclasses = list(g_dict.keys())\n\n# Confusion matrix\ncm = confusion_matrix(test_images.classes, y_pred)\n\nplt.figure(figsize=(30, 30))\nplt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation=45)\nplt.yticks(tick_marks, classes)\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j],\n             horizontalalignment='center',\n             color='white' if cm[i, j] > thresh else 'black')\n\nplt.tight_layout()\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T05:32:30.674774Z","iopub.execute_input":"2025-05-13T05:32:30.675533Z","iopub.status.idle":"2025-05-13T05:32:35.444840Z","shell.execute_reply.started":"2025-05-13T05:32:30.675501Z","shell.execute_reply":"2025-05-13T05:32:35.444090Z"}},"outputs":[],"execution_count":null}]}