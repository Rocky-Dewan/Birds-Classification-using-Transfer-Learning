{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5205289,"sourceType":"datasetVersion","datasetId":3027308}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Environment Setup & Warning Suppression","metadata":{}},{"cell_type":"code","source":"import warnings\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:03:06.988409Z","iopub.execute_input":"2025-05-25T19:03:06.988633Z","iopub.status.idle":"2025-05-25T19:03:07.402516Z","shell.execute_reply.started":"2025-05-25T19:03:06.988609Z","shell.execute_reply":"2025-05-25T19:03:07.401724Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  2. Library Imports & Tools Initialization","metadata":{}},{"cell_type":"code","source":"\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom sklearn.metrics import classification_report, f1_score , confusion_matrix\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:03:07.403324Z","iopub.execute_input":"2025-05-25T19:03:07.403680Z","iopub.status.idle":"2025-05-25T19:03:07.856390Z","shell.execute_reply.started":"2025-05-25T19:03:07.403654Z","shell.execute_reply":"2025-05-25T19:03:07.855623Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Deep Learning Framework Setup & Mixed Precision Configuration","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Rescaling, RandomFlip, RandomRotation, RandomZoom\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import layers, models, Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import mixed_precision\n\nmixed_precision.set_global_policy('mixed_float16')\n\nprint(tf.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:03:07.858183Z","iopub.execute_input":"2025-05-25T19:03:07.858592Z","iopub.status.idle":"2025-05-25T19:03:20.015217Z","shell.execute_reply.started":"2025-05-25T19:03:07.858568Z","shell.execute_reply":"2025-05-25T19:03:20.014499Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Data Loading & Exploration\n## 4.1 Dataset Paths Definition","metadata":{}},{"cell_type":"code","source":"dataset = {\n             \"train_data\" : \"/kaggle/input/indian-birds/Birds_25/train\",\n             \"valid_data\" : \"/kaggle/input/indian-birds/Birds_25/valid\",\n          }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:03:20.018415Z","iopub.execute_input":"2025-05-25T19:03:20.019112Z","iopub.status.idle":"2025-05-25T19:03:20.022588Z","shell.execute_reply.started":"2025-05-25T19:03:20.019068Z","shell.execute_reply":"2025-05-25T19:03:20.021906Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.2 Extracting Image Paths & Labels into DataFrames","metadata":{}},{"cell_type":"code","source":"\n\nall_data = []\nfor path in dataset.values():\n    data = {\"imgpath\": [] , \"labels\": [] }\n    category = os.listdir(path)\n\n    for folder in category:\n        folderpath = os.path.join(path , folder)\n        filelist = os.listdir(folderpath)\n        for file in filelist:\n            fpath = os.path.join(folderpath, file)\n            data[\"imgpath\"].append(fpath)\n            data[\"labels\"].append(folder)\n        \n        \n    all_data.append(data.copy())\n    data.clear()\n\n    \n    \ntrain_df = pd.DataFrame(all_data[0] , index=range(len(all_data[0]['imgpath'])))\nvalid_df = pd.DataFrame(all_data[1] , index=range(len(all_data[1]['imgpath'])))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:03:20.023453Z","iopub.execute_input":"2025-05-25T19:03:20.023718Z","iopub.status.idle":"2025-05-25T19:03:21.867693Z","shell.execute_reply.started":"2025-05-25T19:03:20.023693Z","shell.execute_reply":"2025-05-25T19:03:21.866923Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.3 Label Encoding for Model Compatibility","metadata":{}},{"cell_type":"code","source":"\n\nlb = LabelEncoder()\ntrain_df['encoded_labels'] = lb.fit_transform(train_df['labels'])\nvalid_df['encoded_labels'] = lb.fit_transform(valid_df['labels'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:03:21.868477Z","iopub.execute_input":"2025-05-25T19:03:21.868752Z","iopub.status.idle":"2025-05-25T19:03:21.882535Z","shell.execute_reply.started":"2025-05-25T19:03:21.868725Z","shell.execute_reply":"2025-05-25T19:03:21.881799Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.4 Creating a Test Set from Validation Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n\ndf = pd.concat([train_df, valid_df], ignore_index=True)\n\n\ntrain_val_df, test_df = train_test_split(\n    df,\n    test_size=0.15,\n    shuffle=True,\n    random_state=124\n)\n\n\nval_fraction = 0.15 / 0.85\n\ntrain_df, valid_df = train_test_split(\n    train_val_df,\n    test_size=val_fraction,\n    shuffle=True,\n    random_state=124\n)\n\n\ntrain_df = train_df.reset_index(drop=True)\nvalid_df = valid_df.reset_index(drop=True)\ntest_df  = test_df.reset_index(drop=True)\n\nprint(f\"Train samples:      {len(train_df)}\")   # ~26,250\nprint(f\"Validation samples: {len(valid_df)}\")   # ~5,625\nprint(f\"Test samples:       {len(test_df)}\")    # ~5,625\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:03:21.883175Z","iopub.execute_input":"2025-05-25T19:03:21.883393Z","iopub.status.idle":"2025-05-25T19:03:21.906537Z","shell.execute_reply.started":"2025-05-25T19:03:21.883376Z","shell.execute_reply":"2025-05-25T19:03:21.905960Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  4.5 Visualizing Class Distribution in Training Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nTARGET_COUNT = 1050\nall_classes = train_df['labels'].unique()\n\nbalanced_dataframes = []\n\nfor label in all_classes:\n    subset = train_df[train_df['labels'] == label]\n    count = len(subset)\n    \n    if count > TARGET_COUNT:\n        \n        balanced_subset = subset.sample(n=TARGET_COUNT, replace=False, random_state=42)\n    else:\n        \n        balanced_subset = subset.sample(n=TARGET_COUNT, replace=True, random_state=42)\n    \n    balanced_dataframes.append(balanced_subset)\n\n\ntrain_df = pd.concat(balanced_dataframes).reset_index(drop=True)\n\nprint(\"balanced dataset shape:\", train_df.shape)\nprint(train_df['labels'].value_counts())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ntrain = train_df[\"labels\"].value_counts()\nlabel = train.tolist()\nindex = train.index.tolist()\n\n\nnum_classes = len(index)\ncolors = sns.color_palette(\"hls\", num_classes)  # hls = Hue-Lightness-Saturation \n\nplt.figure(figsize=(10, 10))\nplt.title(\"Training data images count per class\", fontsize=38)\nplt.xlabel('Number of images', fontsize=35)\nplt.ylabel('Classes', fontsize=35)\nplt.barh(index, label, color=colors)\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:03:21.909417Z","iopub.execute_input":"2025-05-25T19:03:21.909656Z","execution_failed":"2025-05-26T04:49:25.514Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  4.6 Sampling & Inspecting Training Data","metadata":{}},{"cell_type":"code","source":"train_df.sample(n=15, random_state=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:03:22.593005Z","iopub.execute_input":"2025-05-25T19:03:22.593920Z","iopub.status.idle":"2025-05-25T19:03:22.610411Z","shell.execute_reply.started":"2025-05-25T19:03:22.593892Z","shell.execute_reply":"2025-05-25T19:03:22.609842Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.7 Data Summary: Sample Records & Dataset Shapes","metadata":{}},{"cell_type":"code","source":"print(\"----------Train-------------\")\nprint(train_df[[\"imgpath\", \"labels\"]].head(5))\nprint(train_df.shape)\nprint(\"--------Validation----------\")\nprint(valid_df[[\"imgpath\", \"labels\"]].head(5))\nprint(valid_df.shape)\nprint(\"----------Test--------------\")\nprint(test_df[[\"imgpath\", \"labels\"]].head(5))\nprint(test_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:03:22.611156Z","iopub.execute_input":"2025-05-25T19:03:22.611375Z","iopub.status.idle":"2025-05-25T19:03:22.623758Z","shell.execute_reply.started":"2025-05-25T19:03:22.611350Z","shell.execute_reply":"2025-05-25T19:03:22.623052Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.8 Image Preview from Validation Set","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,12))\nfor i, row in valid_df.sample(n=16).reset_index().iterrows():\n    plt.subplot(4,4,i+1)\n    image_path = row['imgpath']\n    image = Image.open(image_path)\n    plt.imshow(image)\n    plt.title(row[\"labels\"])\n    plt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:03:22.624460Z","iopub.execute_input":"2025-05-25T19:03:22.624710Z","iopub.status.idle":"2025-05-25T19:03:25.072390Z","shell.execute_reply.started":"2025-05-25T19:03:22.624686Z","shell.execute_reply":"2025-05-25T19:03:25.071130Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Data Preprocessing & Augmentation\n## 5.1 Image Resizing, Preprocessing & Data Generator Setup","metadata":{}},{"cell_type":"code","source":"%%time\n\nBATCH_SIZE = 50\nIMAGE_SIZE = (224, 224)\n\n\ngenerator = ImageDataGenerator(\n    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n    \n)\n\n\ntrain_images = generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='imgpath',\n    y_col='labels',\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=42,\n)\n\nval_images = generator.flow_from_dataframe(\n    dataframe=valid_df,\n    x_col='imgpath',\n    y_col='labels',\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)\n\ntest_images = generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='imgpath',\n    y_col='labels',\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:03:25.073438Z","iopub.execute_input":"2025-05-25T19:03:25.073666Z","iopub.status.idle":"2025-05-25T19:04:59.141322Z","shell.execute_reply.started":"2025-05-25T19:03:25.073642Z","shell.execute_reply":"2025-05-25T19:04:59.140662Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.2 Data Distribution Acrross Classes","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n\nclass_names = list(train_images.class_indices.keys())\n\n\ntrain_counts = train_df['labels'].value_counts().sort_index()\nval_counts = valid_df['labels'].value_counts().sort_index()\ntest_counts = test_df['labels'].value_counts().sort_index()\n\n\nplt.figure(figsize=(18, 8))\nbar_width = 0.25\nindex = np.arange(len(class_names))\n\n\ntrain_bars = plt.bar(index - bar_width, train_counts, bar_width, \n                    label=f'Train ({len(train_df)} images)', color='#1f77b4')\nval_bars = plt.bar(index, val_counts, bar_width, \n                  label=f'Validation ({len(valid_df)} images)', color='#ff7f0e')\ntest_bars = plt.bar(index + bar_width, test_counts, bar_width, \n                   label=f'Test ({len(test_df)} images)', color='#2ca02c')\n\n\nplt.xlabel('Classes', fontsize=12)\nplt.ylabel('Number of Images', fontsize=12)\nplt.title(f'Data Distribution Across Classes (Total: {len(train_df)+len(valid_df)+len(test_df)} images)', fontsize=14)\nplt.xticks(index, class_names, rotation=45, ha='right')\nplt.legend()\n\n\ndef add_labels(bars):\n    for bar in bars:\n        height = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2., height,\n                '%d' % int(height),\n                ha='center', va='bottom', fontsize=8)\n\nadd_labels(train_bars)\nadd_labels(val_bars)\nadd_labels(test_bars)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  6. Model Building\n## 6.1 Load & Freeze Pretrained EfficientNetB3","metadata":{}},{"cell_type":"code","source":"\npretrained_model = tf.keras.applications.EfficientNetB3(\n    input_shape=(224, 224, 3),\n    include_top=False, \n    weights='imagenet',\n    pooling='max'\n)\n\n\nfor i, layer in enumerate(pretrained_model.layers):\n    pretrained_model.layers[i].trainable = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:04:59.141999Z","iopub.execute_input":"2025-05-25T19:04:59.142269Z","iopub.status.idle":"2025-05-25T19:05:05.939061Z","shell.execute_reply.started":"2025-05-25T19:04:59.142250Z","shell.execute_reply":"2025-05-25T19:05:05.938524Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  6.2 Add Augmentation & Compile the Final Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomContrast\n\nnum_classes = len(set(train_images.classes))\n\n\n\naugment = tf.keras.Sequential([\n    RandomFlip(\"horizontal\"),\n    RandomRotation(0.1),\n    RandomZoom(0.1),\n    RandomContrast(0.1),\n], name='AugmentationLayer')\n\n\n\ninputs = layers.Input(shape = (224,224,3), name='inputLayer')\nx = augment(inputs)\npretrain_out = pretrained_model(x, training = False)\nx = layers.Dense(256)(pretrain_out)\nx = layers.Activation(activation=\"relu\")(x) \nx = BatchNormalization()(x)\nx = layers.Dropout(0.3)(x)\nx = layers.Dense(num_classes)(x)\noutputs = layers.Activation(activation=\"softmax\", dtype=tf.float32, name='activationLayer')(x) \nmodel = Model(inputs=inputs, outputs=outputs)\n\n\n\nmodel.compile(\n    optimizer=Adam(0.0005),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(model.summary())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:05:05.939794Z","iopub.execute_input":"2025-05-25T19:05:05.940015Z","iopub.status.idle":"2025-05-25T19:05:06.023646Z","shell.execute_reply.started":"2025-05-25T19:05:05.939989Z","shell.execute_reply":"2025-05-25T19:05:06.023144Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Model Training & Evaluation\n##  7.1 Train the Model with Callbacks","metadata":{}},{"cell_type":"code","source":"    history = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=15,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min')\n    ]\n)\n\n\n#model.save_weights('./checkpoints/my_checkpoint.weights.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:05:06.024320Z","iopub.execute_input":"2025-05-25T19:05:06.024626Z","iopub.status.idle":"2025-05-25T19:30:47.780747Z","shell.execute_reply.started":"2025-05-25T19:05:06.024602Z","shell.execute_reply":"2025-05-25T19:30:47.780148Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  7.2 Save Model Weights to Checkpoint","metadata":{}},{"cell_type":"code","source":"import os\n\n\ncheckpoint_dir = './checkpoints'\nif not os.path.exists(checkpoint_dir):\n    os.makedirs(checkpoint_dir)\n\n\nmodel.save_weights(os.path.join(checkpoint_dir, 'my_checkpoint.weights.h5'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:30:47.781572Z","iopub.execute_input":"2025-05-25T19:30:47.781816Z","iopub.status.idle":"2025-05-25T19:30:48.360626Z","shell.execute_reply.started":"2025-05-25T19:30:47.781799Z","shell.execute_reply":"2025-05-25T19:30:48.359879Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  7.3 Evaluate on Test Dataset","metadata":{}},{"cell_type":"code","source":"results = model.evaluate(test_images, verbose=0)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:30:48.361715Z","iopub.execute_input":"2025-05-25T19:30:48.361940Z","iopub.status.idle":"2025-05-25T19:30:53.490250Z","shell.execute_reply.started":"2025-05-25T19:30:48.361923Z","shell.execute_reply":"2025-05-25T19:30:53.489498Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7.4 Training History Visualization","metadata":{}},{"cell_type":"code","source":"\ntr_acc = history.history['accuracy']\ntr_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n\n\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\n\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:30:53.490994Z","iopub.execute_input":"2025-05-25T19:30:53.491247Z","iopub.status.idle":"2025-05-25T19:30:53.902035Z","shell.execute_reply.started":"2025-05-25T19:30:53.491229Z","shell.execute_reply":"2025-05-25T19:30:53.901288Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 8. Model Performance Analysis\n## 8.1 Classification Report & F1 Score","metadata":{}},{"cell_type":"code","source":"y_true = test_images.classes\ny_pred = np.argmax(model.predict(test_images), axis = 1)\nf1 = f1_score(y_true, y_pred, average='macro')\nprint(\"F1 Score:\", f1)\nprint(classification_report(y_true, y_pred, target_names=test_images.class_indices.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:30:53.902790Z","iopub.execute_input":"2025-05-25T19:30:53.902991Z","iopub.status.idle":"2025-05-25T19:31:07.359763Z","shell.execute_reply.started":"2025-05-25T19:30:53.902976Z","shell.execute_reply":"2025-05-25T19:31:07.359180Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  8.2 Prediction Results Compilation","metadata":{}},{"cell_type":"code","source":"classes = dict(zip(test_images.class_indices.values(), test_images.class_indices.keys()))\nPredictions = pd.DataFrame({\"Image Index\" : list(range(len(test_images.labels))), \n                            \"Test Labels\" : test_images.labels, \n                            \"Test Classes\" : [classes[i] for i in test_images.labels],\n                            \"Prediction Labels\" : y_pred,\n                            \"Prediction Classes\" : [classes[i] for i in y_pred],\n                            \"Path\": test_images.filenames,\n                            \"Prediction Probability\" : [x for x in np.asarray(tf.reduce_max(model.predict(test_images), axis = 1))]\n                           })\nPredictions.head(8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:31:07.360565Z","iopub.execute_input":"2025-05-25T19:31:07.361018Z","iopub.status.idle":"2025-05-25T19:31:10.456654Z","shell.execute_reply.started":"2025-05-25T19:31:07.360997Z","shell.execute_reply":"2025-05-25T19:31:10.456061Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  8.3 Visualization of Misclassified Images","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\nfor i, row in Predictions[Predictions[\"Test Labels\"] != Predictions[\"Prediction Labels\"]].sort_values(\"Prediction Probability\").tail(20).reset_index().iterrows():\n    plt.subplot(5,4,i+1)\n    image_path = row['Path']\n    image = Image.open(image_path)\n    plt.imshow(image)\n    plt.title(f'TRUE: {row[\"Test Classes\"]} | PRED: {row[\"Prediction Classes\"]}', fontsize=8)\n    plt.axis('off')\n    \nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:31:10.457338Z","iopub.execute_input":"2025-05-25T19:31:10.457547Z","iopub.status.idle":"2025-05-25T19:31:14.032867Z","shell.execute_reply.started":"2025-05-25T19:31:10.457527Z","shell.execute_reply":"2025-05-25T19:31:14.031743Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  8.4 Confusion Matrix Visualization","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\n\npreds = model.predict(test_images)  \ny_pred = np.argmax(preds, axis=1)\n\n\ng_dict = test_images.class_indices\nclasses = list(g_dict.keys())\n\n\ncm = confusion_matrix(test_images.classes, y_pred)\n\nplt.figure(figsize=(30, 30))\nplt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation=45)\nplt.yticks(tick_marks, classes)\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j],\n             horizontalalignment='center',\n             color='white' if cm[i, j] > thresh else 'black')\n\nplt.tight_layout()\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:31:14.033708Z","iopub.execute_input":"2025-05-25T19:31:14.033932Z","iopub.status.idle":"2025-05-25T19:31:18.825967Z","shell.execute_reply.started":"2025-05-25T19:31:14.033915Z","shell.execute_reply":"2025-05-25T19:31:18.824411Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 9. Model Fine-tuning & Training\n## 9.1 Fine-tuning Pretrained Model Layers then Re-compiling & Training with Lower Learning Rate","metadata":{}},{"cell_type":"code","source":"pretrained_model.trainable = True\nfor layer in pretrained_model.layers:\n    if isinstance(layer, layers.BatchNormalization): \n        layer.trainable = False\n        \n\nfor l in pretrained_model.layers[:10]:\n    print(l.name, l.trainable)\n\nmodel.compile(\n    optimizer=Adam(0.00001), \n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(model.summary())\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=15,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min')\n    ]\n)\n\n\n#model.save_weights('./checkpoints/my_checkpoint')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:33:48.655548Z","iopub.execute_input":"2025-05-25T19:33:48.656240Z","iopub.status.idle":"2025-05-25T19:59:55.426726Z","shell.execute_reply.started":"2025-05-25T19:33:48.656213Z","shell.execute_reply":"2025-05-25T19:59:55.426144Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9.2 Save Model Weights to Checkpoint","metadata":{}},{"cell_type":"code","source":"import os\n\n\ncheckpoint_dir = './checkpoints'\nif not os.path.exists(checkpoint_dir):\n    os.makedirs(checkpoint_dir)\n\n\nmodel.save_weights(os.path.join(checkpoint_dir, 'my_checkpoint.weights.h5'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:59:55.428034Z","iopub.execute_input":"2025-05-25T19:59:55.428297Z","iopub.status.idle":"2025-05-25T19:59:56.054646Z","shell.execute_reply.started":"2025-05-25T19:59:55.428278Z","shell.execute_reply":"2025-05-25T19:59:56.054016Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9.3 Evaluate on Test Dataset","metadata":{}},{"cell_type":"code","source":"results = model.evaluate(test_images, verbose=0)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:59:56.055621Z","iopub.execute_input":"2025-05-25T19:59:56.055907Z","iopub.status.idle":"2025-05-25T19:59:59.401275Z","shell.execute_reply.started":"2025-05-25T19:59:56.055879Z","shell.execute_reply":"2025-05-25T19:59:59.400485Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9.4 Training History Visualization","metadata":{}},{"cell_type":"code","source":"\ntr_acc = history.history['accuracy']\ntr_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n\n\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\n\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:59:59.403197Z","iopub.execute_input":"2025-05-25T19:59:59.403616Z","iopub.status.idle":"2025-05-25T19:59:59.778112Z","shell.execute_reply.started":"2025-05-25T19:59:59.403596Z","shell.execute_reply":"2025-05-25T19:59:59.777392Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 10. Model Performance Analysis\n## 10.1 Classification Report & F1 Score","metadata":{}},{"cell_type":"code","source":"y_true = test_images.classes\ny_pred = np.argmax(model.predict(test_images), axis = 1)\nf1 = f1_score(y_true, y_pred, average='macro')\nprint(\"F1 Score:\", f1)\nprint(classification_report(y_true, y_pred, target_names=test_images.class_indices.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:59:59.778862Z","iopub.execute_input":"2025-05-25T19:59:59.779055Z","iopub.status.idle":"2025-05-25T20:00:12.895897Z","shell.execute_reply.started":"2025-05-25T19:59:59.779040Z","shell.execute_reply":"2025-05-25T20:00:12.895328Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 10.2 Prediction Results Compilation","metadata":{}},{"cell_type":"code","source":"classes = dict(zip(test_images.class_indices.values(), test_images.class_indices.keys()))\nPredictions = pd.DataFrame({\"Image Index\" : list(range(len(test_images.labels))), \n                            \"Test Labels\" : test_images.labels, \n                            \"Test Classes\" : [classes[i] for i in test_images.labels],\n                            \"Prediction Labels\" : y_pred,\n                            \"Prediction Classes\" : [classes[i] for i in y_pred],\n                            \"Path\": test_images.filenames,\n                            \"Prediction Probability\" : [x for x in np.asarray(tf.reduce_max(model.predict(test_images), axis = 1))]\n                           })\nPredictions.head(8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:01:19.801336Z","iopub.execute_input":"2025-05-25T20:01:19.802037Z","iopub.status.idle":"2025-05-25T20:01:22.937478Z","shell.execute_reply.started":"2025-05-25T20:01:19.802011Z","shell.execute_reply":"2025-05-25T20:01:22.936673Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 10.3 Visualization of Misclassified Images","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\nfor i, row in Predictions[Predictions[\"Test Labels\"] != Predictions[\"Prediction Labels\"]].sort_values(\"Prediction Probability\").tail(20).reset_index().iterrows():\n    plt.subplot(5,4,i+1)\n    image_path = row['Path']\n    image = Image.open(image_path)\n    plt.imshow(image)\n    plt.title(f'TRUE: {row[\"Test Classes\"]} | PRED: {row[\"Prediction Classes\"]}', fontsize=8)\n    plt.axis('off')\n    \nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:01:29.604388Z","iopub.execute_input":"2025-05-25T20:01:29.604902Z","iopub.status.idle":"2025-05-25T20:01:33.198624Z","shell.execute_reply.started":"2025-05-25T20:01:29.604879Z","shell.execute_reply":"2025-05-25T20:01:33.197471Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  10.4 Confusion Matrix Visualization ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\n\npreds = model.predict(test_images)  \ny_pred = np.argmax(preds, axis=1)\n\n\ng_dict = test_images.class_indices\nclasses = list(g_dict.keys())\n\n\ncm = confusion_matrix(test_images.classes, y_pred)\n\nplt.figure(figsize=(30, 30))\nplt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation=45)\nplt.yticks(tick_marks, classes)\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j],\n             horizontalalignment='center',\n             color='white' if cm[i, j] > thresh else 'black')\n\nplt.tight_layout()\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:01:33.200350Z","iopub.execute_input":"2025-05-25T20:01:33.200681Z","iopub.status.idle":"2025-05-25T20:01:37.986629Z","shell.execute_reply.started":"2025-05-25T20:01:33.200651Z","shell.execute_reply":"2025-05-25T20:01:37.985970Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 11.Custom Model Building with EfficientNetB3\n## 11.1 Advanced Data Augmentation Layer with Model Architecture and Initial Training (Frozen Base)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import BatchNormalization, Dropout\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n\npretrained_model = EfficientNetB3(include_top=False, input_shape=(224, 224, 3), pooling='avg')\n\n\nnum_classes = len(set(train_images.classes))\n\n\naugment = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.15),\n    layers.RandomZoom(0.2),\n    layers.RandomContrast(0.2),\n], name='AugmentationLayer')\n\n\ninputs = layers.Input(shape=(224, 224, 3), name='inputLayer')\n\n\nx = augment(inputs)\n\n\nx = layers.Rescaling(1./255)(x)\n\n\nx = pretrained_model(x, training=False)\n\n\nx = layers.Dense(512)(x)\nx = layers.LeakyReLU()(x)\nx = Dropout(0.4)(x)\nx = BatchNormalization()(x)\n\nx = layers.Dense(256, activation='relu')(x)\nx = Dropout(0.3)(x)\n\nx = layers.Dense(128, activation='relu')(x)\n\n\nx = layers.Dense(num_classes)(x)\noutputs = layers.Activation(\"softmax\", dtype=tf.float32, name='activationLayer')(x)\n\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\n\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0005),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nmodel.summary()\n\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=15,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min')\n    ]\n)\n\n\n# model.save_weights('./checkpoints/efficientnetb3_custom_checkpoint.h5')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:01:37.987556Z","iopub.execute_input":"2025-05-25T20:01:37.988076Z","iopub.status.idle":"2025-05-25T20:47:26.735658Z","shell.execute_reply.started":"2025-05-25T20:01:37.988050Z","shell.execute_reply":"2025-05-25T20:47:26.734875Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11.2 Evaluate on Test Dataset","metadata":{}},{"cell_type":"code","source":"results = model.evaluate(test_images, verbose=0)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:47:26.737424Z","iopub.execute_input":"2025-05-25T20:47:26.737636Z","iopub.status.idle":"2025-05-25T20:47:30.163728Z","shell.execute_reply.started":"2025-05-25T20:47:26.737619Z","shell.execute_reply":"2025-05-25T20:47:30.162963Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11.3 Training History Visualization","metadata":{}},{"cell_type":"code","source":"\ntr_acc = history.history['accuracy']\ntr_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n\n\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\n\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:47:30.164595Z","iopub.execute_input":"2025-05-25T20:47:30.165344Z","iopub.status.idle":"2025-05-25T20:47:30.574117Z","shell.execute_reply.started":"2025-05-25T20:47:30.165322Z","shell.execute_reply":"2025-05-25T20:47:30.573406Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11.3 Classification Report & F1 Score","metadata":{}},{"cell_type":"code","source":"y_true = test_images.classes\ny_pred = np.argmax(model.predict(test_images), axis = 1)\nf1 = f1_score(y_true, y_pred, average='macro')\nprint(\"F1 Score:\", f1)\nprint(classification_report(y_true, y_pred, target_names=test_images.class_indices.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:47:30.574889Z","iopub.execute_input":"2025-05-25T20:47:30.575223Z","iopub.status.idle":"2025-05-25T20:47:45.216727Z","shell.execute_reply.started":"2025-05-25T20:47:30.575205Z","shell.execute_reply":"2025-05-25T20:47:45.216131Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11.4 Training and Validation Curve Visualization for Custom CNN EfficientNetB3 Model","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_training_curves(history, model_name):\n    loss = np.array(history.history['loss'])\n    val_loss = np.array(history.history['val_loss'])\n    accuracy = np.array(history.history['accuracy'])\n    val_accuracy = np.array(history.history['val_accuracy'])\n    epochs = range(len(loss))\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n    fig.suptitle(f'Training Curves for {model_name}', fontsize=16)\n\n \n    ax1.plot(epochs, loss, label='Training Loss', marker='o')\n    ax1.plot(epochs, val_loss, label='Validation Loss', marker='o')\n    ax1.fill_between(epochs, loss, val_loss, where=(loss > val_loss), color='C0', alpha=0.3, interpolate=True)\n    ax1.fill_between(epochs, loss, val_loss, where=(loss < val_loss), color='C1', alpha=0.3, interpolate=True)\n    ax1.set_title('Loss (Lower is Better)', fontsize=14)\n    ax1.set_xlabel('Epochs', fontsize=12)\n    ax1.set_ylabel('Loss', fontsize=12)\n    ax1.legend()\n\n\n    ax2.plot(epochs, accuracy, label='Training Accuracy', marker='o')\n    ax2.plot(epochs, val_accuracy, label='Validation Accuracy', marker='o')\n    ax2.fill_between(epochs, accuracy, val_accuracy, where=(accuracy > val_accuracy), color='C0', alpha=0.3, interpolate=True)\n    ax2.fill_between(epochs, accuracy, val_accuracy, where=(accuracy < val_accuracy), color='C1', alpha=0.3, interpolate=True)\n    ax2.set_title('Accuracy (Higher is Better)', fontsize=14)\n    ax2.set_xlabel('Epochs', fontsize=12)\n    ax2.set_ylabel('Accuracy', fontsize=12)\n    ax2.legend()\n\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_training_curves(history, 'Custom CNN EfficientNetB3 Model')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11.5 Epoch-wise Gain vs. Loss Delta Plot","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n\ndelta_val_acc = np.diff(val_acc)\ndelta_val_loss = -np.diff(val_loss)  \nepochs = list(range(2, len(val_acc)+1)) \nplt.figure(figsize=(12, 6))\nplt.plot(epochs, delta_val_acc, label='Δ Validation Accuracy', marker='o', color='green')\nplt.plot(epochs, delta_val_loss, label='-Δ Validation Loss', marker='s', color='orange')\n\nplt.axhline(0, color='gray', linestyle='--', linewidth=1)\n\nplt.title('Epoch-wise Change in Validation Accuracy and Loss', fontsize=18)\nplt.xlabel('Epoch', fontsize=14)\nplt.ylabel('Change Value', fontsize=14)\nplt.legend(fontsize=12)\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11.6 Model Confidence Histogram","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n\npred_probs = model.predict(test_images)\nconfidences = np.max(pred_probs, axis=1)\n\nplt.figure(figsize=(10, 6))\nplt.hist(confidences, bins=30, color='teal', edgecolor='black')\nplt.title('Model Confidence Histogram', fontsize=16)\nplt.xlabel('Predicted Probability (Confidence)', fontsize=14)\nplt.ylabel('Number of Samples', fontsize=14)\nplt.grid(axis='y')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11.7 Misclassification Heatmap","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\n\ntrue_labels = test_images.classes\npred_labels = np.argmax(pred_probs, axis=1)\nclass_names = list(test_images.class_indices.keys())\n\n\ncm = confusion_matrix(true_labels, pred_labels)\n\n\ncm_mis = cm.copy()\nnp.fill_diagonal(cm_mis, 0)\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm_mis, annot=True, fmt='d', cmap='Reds', xticklabels=class_names, yticklabels=class_names)\nplt.title('Misclassification Heatmap', fontsize=18)\nplt.xlabel('Predicted Label', fontsize=14)\nplt.ylabel('True Label', fontsize=14)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11.8 Prediction Results Compilation","metadata":{}},{"cell_type":"code","source":"classes = dict(zip(test_images.class_indices.values(), test_images.class_indices.keys()))\nPredictions = pd.DataFrame({\"Image Index\" : list(range(len(test_images.labels))), \n                            \"Test Labels\" : test_images.labels, \n                            \"Test Classes\" : [classes[i] for i in test_images.labels],\n                            \"Prediction Labels\" : y_pred,\n                            \"Prediction Classes\" : [classes[i] for i in y_pred],\n                            \"Path\": test_images.filenames,\n                            \"Prediction Probability\" : [x for x in np.asarray(tf.reduce_max(model.predict(test_images), axis = 1))]\n                           })\nPredictions.head(8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:47:45.217399Z","iopub.execute_input":"2025-05-25T20:47:45.217585Z","iopub.status.idle":"2025-05-25T20:47:48.220971Z","shell.execute_reply.started":"2025-05-25T20:47:45.217571Z","shell.execute_reply":"2025-05-25T20:47:48.220249Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11.9 Visualization of Misclassified Images","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\nfor i, row in Predictions[Predictions[\"Test Labels\"] != Predictions[\"Prediction Labels\"]].sort_values(\"Prediction Probability\").tail(20).reset_index().iterrows():\n    plt.subplot(5,4,i+1)\n    image_path = row['Path']\n    image = Image.open(image_path)\n    plt.imshow(image)\n    plt.title(f'TRUE: {row[\"Test Classes\"]} | PRED: {row[\"Prediction Classes\"]}', fontsize=8)\n    plt.axis('off')\n    \nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:47:48.221815Z","iopub.execute_input":"2025-05-25T20:47:48.222582Z","iopub.status.idle":"2025-05-25T20:47:48.996307Z","shell.execute_reply.started":"2025-05-25T20:47:48.222554Z","shell.execute_reply":"2025-05-25T20:47:48.995598Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11.10 Confusion Matrix Visualization","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\n\npreds = model.predict(test_images)  \ny_pred = np.argmax(preds, axis=1)\n\n\ng_dict = test_images.class_indices\nclasses = list(g_dict.keys())\n\n\ncm = confusion_matrix(test_images.classes, y_pred)\n\nplt.figure(figsize=(30, 30))\nplt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation=45)\nplt.yticks(tick_marks, classes)\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j],\n             horizontalalignment='center',\n             color='white' if cm[i, j] > thresh else 'black')\n\nplt.tight_layout()\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:47:48.998553Z","iopub.execute_input":"2025-05-25T20:47:48.998967Z","iopub.status.idle":"2025-05-25T20:47:53.714436Z","shell.execute_reply.started":"2025-05-25T20:47:48.998945Z","shell.execute_reply":"2025-05-25T20:47:53.713479Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 12. Transfer Learning with ResNet152V2\n## 12.1 Model Initialization (Pretrained + Frozen) with Custom Classification Head and Unfreezing Base Model & Recompilation and Fine-Tuning","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import ResNet152V2\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n\nbase_model = ResNet152V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\nbase_model.trainable = False  \n\n\ndata_augmentation = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomZoom(0.1),\n    layers.RandomTranslation(0.1, 0.1),\n    layers.RandomContrast(0.2),\n], name=\"data_augmentation\")\n\n\ninputs = layers.Input(shape=(224, 224, 3))\nx = data_augmentation(inputs)\nx = layers.Rescaling(1./255)(x)\nx = base_model(x, training=False)\nx = layers.GlobalAveragePooling2D()(x)\n\n\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.5)(x)\nx = layers.Dense(512, activation='relu')(x)\nx = layers.Dropout(0.3)(x)\nx = layers.Dense(num_classes, activation='softmax')(x)\n\nmodel = models.Model(inputs, x)\n\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=15,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.3, patience=2)\n    ]\n)\n\n\nbase_model.trainable = True\nfor layer in base_model.layers:\n    if isinstance(layer, layers.BatchNormalization):\n        layer.trainable = False\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nhistory_finetune = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=15,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.3, patience=2)\n    ]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T21:28:55.295679Z","iopub.execute_input":"2025-05-25T21:28:55.295961Z","iopub.status.idle":"2025-05-25T23:07:46.030384Z","shell.execute_reply.started":"2025-05-25T21:28:55.295939Z","shell.execute_reply":"2025-05-25T23:07:46.029749Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 12.2 Evaluate on Test Dataset","metadata":{}},{"cell_type":"code","source":"results = model.evaluate(test_images, verbose=0)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0])) \nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T23:07:51.265908Z","iopub.execute_input":"2025-05-25T23:07:51.266627Z","iopub.status.idle":"2025-05-25T23:07:54.930503Z","shell.execute_reply.started":"2025-05-25T23:07:51.266592Z","shell.execute_reply":"2025-05-25T23:07:54.929837Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 12.4 Classification Report & F1 Score","metadata":{}},{"cell_type":"code","source":"y_true = test_images.classes\ny_pred = np.argmax(model.predict(test_images), axis = 1)\nf1 = f1_score(y_true, y_pred, average='macro')\nprint(\"F1 Score:\", f1)\nprint(classification_report(y_true, y_pred, target_names=test_images.class_indices.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T23:08:18.517878Z","iopub.execute_input":"2025-05-25T23:08:18.518396Z","iopub.status.idle":"2025-05-25T23:08:36.450184Z","shell.execute_reply.started":"2025-05-25T23:08:18.518371Z","shell.execute_reply":"2025-05-25T23:08:36.449553Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 12.3 Training History Visualization","metadata":{}},{"cell_type":"code","source":"\ntr_acc = history.history['accuracy']\ntr_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n\n\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\n\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T23:08:01.020018Z","iopub.execute_input":"2025-05-25T23:08:01.020723Z","iopub.status.idle":"2025-05-25T23:08:01.424385Z","shell.execute_reply.started":"2025-05-25T23:08:01.020697Z","shell.execute_reply":"2025-05-25T23:08:01.423712Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 12.5 Prediction Results Compilation","metadata":{}},{"cell_type":"code","source":"classes = dict(zip(test_images.class_indices.values(), test_images.class_indices.keys()))\nPredictions = pd.DataFrame({\"Image Index\" : list(range(len(test_images.labels))), \n                            \"Test Labels\" : test_images.labels, \n                            \"Test Classes\" : [classes[i] for i in test_images.labels],\n                            \"Prediction Labels\" : y_pred,\n                            \"Prediction Classes\" : [classes[i] for i in y_pred],\n                            \"Path\": test_images.filenames,\n                            \"Prediction Probability\" : [x for x in np.asarray(tf.reduce_max(model.predict(test_images), axis = 1))]\n                           })\nPredictions.head(8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T23:08:42.954693Z","iopub.execute_input":"2025-05-25T23:08:42.955244Z","iopub.status.idle":"2025-05-25T23:08:46.038807Z","shell.execute_reply.started":"2025-05-25T23:08:42.955221Z","shell.execute_reply":"2025-05-25T23:08:46.038219Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 12.6 Visualization of Misclassified Images","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\nfor i, row in Predictions[Predictions[\"Test Labels\"] != Predictions[\"Prediction Labels\"]].sort_values(\"Prediction Probability\").tail(20).reset_index().iterrows():\n    plt.subplot(5,4,i+1)\n    image_path = row['Path']\n    image = Image.open(image_path)\n    plt.imshow(image)\n    plt.title(f'TRUE: {row[\"Test Classes\"]} | PRED: {row[\"Prediction Classes\"]}', fontsize=8)\n    plt.axis('off')\n    \nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T23:08:51.119720Z","iopub.execute_input":"2025-05-25T23:08:51.120375Z","iopub.status.idle":"2025-05-25T23:08:52.464671Z","shell.execute_reply.started":"2025-05-25T23:08:51.120354Z","shell.execute_reply":"2025-05-25T23:08:52.463849Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 12.7 Confusion Matrix Visualization","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\n\npreds = model.predict(test_images)  \ny_pred = np.argmax(preds, axis=1)\n\n\ng_dict = test_images.class_indices\nclasses = list(g_dict.keys())\n\n\ncm = confusion_matrix(test_images.classes, y_pred)\n\nplt.figure(figsize=(30, 30))\nplt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation=45)\nplt.yticks(tick_marks, classes)\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j],\n             horizontalalignment='center',\n             color='white' if cm[i, j] > thresh else 'black')\n\nplt.tight_layout()\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T23:09:08.959783Z","iopub.execute_input":"2025-05-25T23:09:08.960054Z","iopub.status.idle":"2025-05-25T23:09:13.834617Z","shell.execute_reply.started":"2025-05-25T23:09:08.960034Z","shell.execute_reply":"2025-05-25T23:09:13.833901Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 13. Training and Validation Curve Visualization for ResNet152V2 Model","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_training_curves(history, model_name):\n    loss = np.array(history.history['loss'])\n    val_loss = np.array(history.history['val_loss'])\n    accuracy = np.array(history.history['accuracy'])\n    val_accuracy = np.array(history.history['val_accuracy'])\n    epochs = range(len(loss))\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n    fig.suptitle(f'Training Curves for {model_name}', fontsize=16)\n\n \n    ax1.plot(epochs, loss, label='Training Loss', marker='o')\n    ax1.plot(epochs, val_loss, label='Validation Loss', marker='o')\n    ax1.fill_between(epochs, loss, val_loss, where=(loss > val_loss), color='C0', alpha=0.3, interpolate=True)\n    ax1.fill_between(epochs, loss, val_loss, where=(loss < val_loss), color='C1', alpha=0.3, interpolate=True)\n    ax1.set_title('Loss (Lower is Better)', fontsize=14)\n    ax1.set_xlabel('Epochs', fontsize=12)\n    ax1.set_ylabel('Loss', fontsize=12)\n    ax1.legend()\n\n\n    ax2.plot(epochs, accuracy, label='Training Accuracy', marker='o')\n    ax2.plot(epochs, val_accuracy, label='Validation Accuracy', marker='o')\n    ax2.fill_between(epochs, accuracy, val_accuracy, where=(accuracy > val_accuracy), color='C0', alpha=0.3, interpolate=True)\n    ax2.fill_between(epochs, accuracy, val_accuracy, where=(accuracy < val_accuracy), color='C1', alpha=0.3, interpolate=True)\n    ax2.set_title('Accuracy (Higher is Better)', fontsize=14)\n    ax2.set_xlabel('Epochs', fontsize=12)\n    ax2.set_ylabel('Accuracy', fontsize=12)\n    ax2.legend()\n\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T04:03:56.811188Z","iopub.execute_input":"2025-05-27T04:03:56.811438Z","iopub.status.idle":"2025-05-27T04:03:56.822802Z","shell.execute_reply.started":"2025-05-27T04:03:56.811420Z","shell.execute_reply":"2025-05-27T04:03:56.822258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nplot_training_curves(history, 'ResNet152V2 Model')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T23:10:25.770345Z","iopub.execute_input":"2025-05-25T23:10:25.770639Z","iopub.status.idle":"2025-05-25T23:10:26.180052Z","shell.execute_reply.started":"2025-05-25T23:10:25.770619Z","shell.execute_reply":"2025-05-25T23:10:26.179322Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 14. Training History Visualization","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_finetuning_performance(history, model_name=\"Fine-tuned Model\"):\n    tr_acc = history.history['accuracy']\n    tr_loss = history.history['loss']\n    val_acc = history.history['val_accuracy']\n    val_loss = history.history['val_loss']\n\n    index_loss = np.argmin(val_loss)\n    val_lowest = val_loss[index_loss]\n\n    index_acc = np.argmax(val_acc)\n    acc_highest = val_acc[index_acc]\n\n    epochs = [i + 1 for i in range(len(tr_acc))]\n    loss_label = f'Best Epoch = {index_loss + 1}'\n    acc_label = f'Best Epoch = {index_acc + 1}'\n\n    plt.figure(figsize=(20, 8))\n    plt.style.use('fivethirtyeight')\n\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, tr_loss, 'r', label='Training Loss')\n    plt.plot(epochs, val_loss, 'g', label='Validation Loss')\n    plt.scatter(index_loss + 1, val_lowest, s=150, c='blue', label=loss_label)\n    plt.title(f'{model_name} - Loss Curve')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, tr_acc, 'r', label='Training Accuracy')\n    plt.plot(epochs, val_acc, 'g', label='Validation Accuracy')\n    plt.scatter(index_acc + 1, acc_highest, s=150, c='blue', label=acc_label)\n    plt.title(f'{model_name} - Accuracy Curve')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T04:04:16.304977Z","iopub.execute_input":"2025-05-27T04:04:16.305504Z","iopub.status.idle":"2025-05-27T04:04:16.313318Z","shell.execute_reply.started":"2025-05-27T04:04:16.305480Z","shell.execute_reply":"2025-05-27T04:04:16.312631Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 15. Training and Validation Curve Visualization for ResNet152V2 Model After Fine-Tuning","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_finetuning_curves(history_finetune, model_name):\n    loss = np.array(history_finetune.history['loss'])\n    val_loss = np.array(history_finetune.history['val_loss'])\n    accuracy = np.array(history_finetune.history['accuracy'])\n    val_accuracy = np.array(history_finetune.history['val_accuracy'])\n    epochs = range(len(loss))\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n    fig.suptitle(f'Fine-Tuning Curves for {model_name}', fontsize=16)\n\n    ax1.plot(epochs, loss, label='Training Loss', marker='o', color='blue')\n    ax1.plot(epochs, val_loss, label='Validation Loss', marker='o', color='orange')\n    ax1.set_title('Loss During Fine-Tuning', fontsize=14)\n    ax1.set_xlabel('Epochs', fontsize=12)\n    ax1.set_ylabel('Loss', fontsize=12)\n    ax1.legend()\n    ax1.grid(True)\n\n    ax2.plot(epochs, accuracy, label='Training Accuracy', marker='o', color='green')\n    ax2.plot(epochs, val_accuracy, label='Validation Accuracy', marker='o', color='red')\n    ax2.set_title('Accuracy During Fine-Tuning', fontsize=14)\n    ax2.set_xlabel('Epochs', fontsize=12)\n    ax2.set_ylabel('Accuracy', fontsize=12)\n    ax2.legend()\n    ax2.grid(True)\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T04:04:21.695375Z","iopub.execute_input":"2025-05-27T04:04:21.695626Z","iopub.status.idle":"2025-05-27T04:04:21.702326Z","shell.execute_reply.started":"2025-05-27T04:04:21.695608Z","shell.execute_reply":"2025-05-27T04:04:21.701587Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_finetuning_curves(history_finetune, \"ResNet50 Fine-Tuned\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T04:04:26.903410Z","iopub.execute_input":"2025-05-27T04:04:26.903707Z","iopub.status.idle":"2025-05-27T04:04:26.968924Z","shell.execute_reply.started":"2025-05-27T04:04:26.903686Z","shell.execute_reply":"2025-05-27T04:04:26.968157Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 16. Visualization ROC and AUC Curves (Multiclass)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom itertools import cycle\n\n\nclass_names = list(test_images.class_indices.keys())\nn_classes = len(class_names)\n\n\ny_true = test_images.classes\ny_score = model.predict(test_images)\ny_test = label_binarize(y_true, classes=range(n_classes))  \n\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n\nplt.figure(figsize=(20, 15))\ncolors = cycle(plt.cm.tab10.colors)  \n\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label=f'ROC curve of class {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)  \nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=14)\nplt.ylabel('True Positive Rate', fontsize=14)\nplt.title('ROC Curves for Each Class', fontsize=16)\nplt.legend(loc='lower right', fontsize=12)\nplt.grid(alpha=0.3)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 17. Micro & Macro Average ROC Curve","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import RocCurveDisplay\nfrom numpy import interp\nfrom itertools import cycle\n\n\nclass_names = list(test_images.class_indices.keys())\nn_classes = len(class_names)\n\n\ny_true = test_images.classes\ny_score = model.predict(test_images)\n\n\ny_test = label_binarize(y_true, classes=range(n_classes))\n\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n\nmean_tpr /= n_classes\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T08:46:19.776101Z","iopub.execute_input":"2025-06-13T08:46:19.776317Z","iopub.status.idle":"2025-06-13T08:46:21.177860Z","shell.execute_reply.started":"2025-06-13T08:46:19.776299Z","shell.execute_reply":"2025-06-13T08:46:21.176804Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 18. ROC Curve: Micro, Macro, Per Class","metadata":{}},{"cell_type":"code","source":"\nplt.figure(figsize=(20, 15))\n\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label=f'Macro-average ROC (AUC = {roc_auc[\"macro\"]:.2f})',\n         color='navy', linestyle=':', linewidth=4)\n\n\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label=f'Micro-average ROC (AUC = {roc_auc[\"micro\"]:.2f})',\n         color='deeppink', linestyle=':', linewidth=4)\n\n\ncolors = cycle(plt.cm.tab20.colors)\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label=f'ROC for class {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\n\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=14)\nplt.ylabel('True Positive Rate', fontsize=14)\nplt.title('ROC Curves: Micro, Macro and Per-Class', fontsize=16)\nplt.legend(loc='lower right', fontsize=12)\nplt.grid(alpha=0.3)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Improved results may be achived through ensembling techniques (such as blending, stacking or voting)**","metadata":{}}]}
